{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mEmz5T8EER9",
        "outputId": "0e2b7380-18ff-4748-c3d2-731972d2f604"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Collecting h5py>=3.10.0 (from tensorflow)\n",
            "  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow)\n",
            "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
            "Collecting tensorboard<2.17,>=2.16 (from tensorflow)\n",
            "  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras>=3.0.0 (from tensorflow)\n",
            "  Downloading keras-3.2.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
            "Collecting namex (from keras>=3.0.0->tensorflow)\n",
            "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Collecting optree (from keras>=3.0.0->tensorflow)\n",
            "  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
            "Installing collected packages: namex, optree, ml-dtypes, h5py, tensorboard, keras, tensorflow\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.2.0\n",
            "    Uninstalling ml-dtypes-0.2.0:\n",
            "      Successfully uninstalled ml-dtypes-0.2.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.9.0\n",
            "    Uninstalling h5py-3.9.0:\n",
            "      Successfully uninstalled h5py-3.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h5py-3.11.0 keras-3.2.1 ml-dtypes-0.3.2 namex-0.0.8 optree-0.11.0 tensorboard-2.16.2 tensorflow-2.16.1\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)  # This will print the version of TensorFlow being used.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iht33asrEO-a",
        "outputId": "b779ee32-d4e8-4ca5-b80b-bf2993b78450"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.16.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "import json\n"
      ],
      "metadata": {
        "id": "teld1XyxFCSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_FOLDER = '/content/data/'  # Adjusted path for Colab\n",
        "POSE_CLASSES = ['chair', 'cobra', 'dog', 'tree', 'warrior']\n",
        "MODEL_FILENAME = '/content/yoga_pose_model2.h5'  # Adjusted path for Colab\n"
      ],
      "metadata": {
        "id": "09455KnbFITY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(pose_class):\n",
        "    filepath = f'{DATA_FOLDER}{pose_class}_data.json'  # Direct string concatenation\n",
        "    with open(filepath, 'r') as file:\n",
        "        data = json.load(file)\n",
        "    df = json_to_dataframe(data)\n",
        "\n",
        "    df['label'] = pose_class\n",
        "    print(f\"Loaded {df.shape[0]} items for class '{pose_class}'\")\n",
        "\n",
        "    return df\n",
        "\n"
      ],
      "metadata": {
        "id": "HMpWS-acF7uk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def json_to_dataframe(data):\n",
        "    rows = []\n",
        "    # Iterate through each item in the JSON data\n",
        "    for filename, attributes in data.items():\n",
        "        # Initialize a dictionary for storing features\n",
        "        row = {'image': filename}\n",
        "        # Check if 'features' is a key in your JSON structure\n",
        "        features = attributes.get('features', {})\n",
        "        # Iterate through each body part in the features\n",
        "        for part, feature in features.items():\n",
        "            # Extract coordinates and score\n",
        "            coordinates = feature.get('coordinates', {})\n",
        "            score = feature.get('score', None)\n",
        "            # Add to the row dictionary\n",
        "            row[f'{part}_x'] = coordinates.get('x', None)\n",
        "            row[f'{part}_y'] = coordinates.get('y', None)\n",
        "            row[f'{part}_score'] = score\n",
        "        rows.append(row)\n",
        "    # Convert rows to DataFrame\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KlNOGXgiHMSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset():\n",
        "    frames = [load_data(pose_class) for pose_class in POSE_CLASSES]\n",
        "    full_df = pd.concat(frames, ignore_index=True)\n",
        "\n",
        "    # Convert labels to categorical\n",
        "    full_df['label'] = pd.Categorical(full_df['label'])\n",
        "    full_df['label'] = full_df['label'].cat.codes\n",
        "\n",
        "    # Split data...\n",
        "    X = full_df.drop(['label'], axis=1)  # Assuming 'label' is the only non-feature column\n",
        "    y = full_df['label']\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
        "\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test\n"
      ],
      "metadata": {
        "id": "7gUq2folHaoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "\n",
        "def build_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Input(shape=(input_shape,)),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),  # Lower learning rate\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "er4gwkbmHciO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, X_test, y_train, y_val, y_test = prepare_dataset()\n",
        "\n",
        "# Assuming one-hot encoding for the categorical labels\n",
        "y_train_encoded = to_categorical(y_train)\n",
        "y_val_encoded = to_categorical(y_val)\n",
        "\n",
        "model = build_model(X_train.shape[1], len(POSE_CLASSES))\n",
        "\n",
        "print(X_train.dtypes)\n",
        "X_train = X_train.apply(pd.to_numeric, errors='coerce')\n",
        "X_val = X_val.apply(pd.to_numeric, errors='coerce')\n",
        "X_test = X_test.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Check if there are any NaN values after conversion\n",
        "print(X_train.isna().sum())\n",
        "\n",
        "# Fill NaN values with the mean (or another statistic) of each column\n",
        "X_train.fillna(X_train.mean(), inplace=True)\n",
        "X_val.fillna(X_train.mean(), inplace=True)  # Use training data's statistics for validation set\n",
        "X_test.fillna(X_train.mean(), inplace=True)  # and for test set\n",
        "\n",
        "# Recheck dtypes to confirm all are now float64 or a similar numeric type\n",
        "print(X_train.dtypes)\n",
        "\n",
        "\n",
        "history = model.fit(X_train, y_train_encoded, epochs=10, validation_data=(X_val, y_val_encoded))\n",
        "\n",
        "test_loss, test_acc = model.evaluate(X_test, to_categorical(y_test))\n",
        "print(f'Test accuracy: {test_acc}')\n",
        "\n",
        "# Save the model to the Colab file system\n",
        "model.save(MODEL_FILENAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtI473KJHf-2",
        "outputId": "db61a13d-6871-4c40-9e64-dcbc7a7e5668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 200 items for class 'chair'\n",
            "Loaded 200 items for class 'cobra'\n",
            "Loaded 200 items for class 'dog'\n",
            "Loaded 200 items for class 'tree'\n",
            "Loaded 199 items for class 'warrior'\n",
            "image    object\n",
            "dtype: object\n",
            "image    599\n",
            "dtype: int64\n",
            "image    float64\n",
            "dtype: object\n",
            "Epoch 1/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.1912 - loss: nan - val_accuracy: 0.2050 - val_loss: nan\n",
            "Epoch 2/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1978 - loss: nan - val_accuracy: 0.2050 - val_loss: nan\n",
            "Epoch 3/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1904 - loss: nan - val_accuracy: 0.2050 - val_loss: nan\n",
            "Epoch 4/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2214 - loss: nan - val_accuracy: 0.2050 - val_loss: nan\n",
            "Epoch 5/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1880 - loss: nan - val_accuracy: 0.2050 - val_loss: nan\n",
            "Epoch 6/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2161 - loss: nan - val_accuracy: 0.2050 - val_loss: nan\n",
            "Epoch 7/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2110 - loss: nan - val_accuracy: 0.2050 - val_loss: nan\n",
            "Epoch 8/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1937 - loss: nan - val_accuracy: 0.2050 - val_loss: nan\n",
            "Epoch 9/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1967 - loss: nan - val_accuracy: 0.2050 - val_loss: nan\n",
            "Epoch 10/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2127 - loss: nan - val_accuracy: 0.2050 - val_loss: nan\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1622 - loss: nan \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.16500000655651093\n"
          ]
        }
      ]
    }
  ]
}